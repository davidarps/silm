--config_name
configs/zh/babylmrobertaconfig.json
--output_dir
models/zh/roberta_1/
--train_file
data/zh/train.txt
--validation_file
data/zh/val.txt
--tokenizer_name
tokenizers/chinese_babylm_10K/
--line_by_line
True
--pad_to_max_length
--max_seq_length
96
--num_processes
8
--checkpointing_steps
1000
--per_device_train_batch_size
1024
--gradient_accumulation_steps
1
--num_train_epochs
250
--with_tracking
--report_to
tensorboard
--objective_function
mlm
--mixed_precision
bf16
--learning_rate
5e-4
--num_warmup_steps
1000